# chatllm

**chatllm** is an extended version of the [FastChat](https://github.com/lm-sys/FastChat) project, integrating an embedding worker for pre-trained embedding models. This enhances the chat experience by incorporating advanced embedding techniques.

## Features

- **FastChat Core Functionality:** Inherits core features from FastChat, including large language model-based chatbots, real-time messaging, user authentication, and customizable settings.
- **Embedding Worker Integration:** Incorporates pre-trained embedding models for semantic understanding and contextual relevance.
- **Extended Model Compatibility:** Supports various embedding models from Hugging Face's model hub.
- **Scalability:** Seamlessly integrates embedding workers for efficient processing of chat data.

## Deployment

1. Clone the **chatllm** repository:

    ```bash
    git clone https://github.com/kimnt93/chatllm.git
    ```

2. Navigate to the project directory:

    ```bash
    cd chatllm
    ```

3. Run Docker Compose:

    ```bash
    docker-compose up -d
    ```

## Contributing

Contributions to **chatllm** are welcome! Please refer to the project's repository for guidelines.

## License

**chatllm** is licensed under the [GNU General Public License v3.0](LICENSE).

## Contact

For questions or feedback, contact us at [kimnt93@gmail.com](mailto:kimnt93@gmail.com). We value your input!